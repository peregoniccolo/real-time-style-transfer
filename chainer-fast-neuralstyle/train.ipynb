{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1999,"status":"ok","timestamp":1690125144705,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"ZSgbg_GYGfYy","outputId":"a9c65f29-ab85-4b1e-90d8-f8ee55e83177"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1690125144705,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"ZrDrvUwHG1Am","outputId":"9fedcb74-a14f-4cf2-afe7-8741bb8b90b2"},"outputs":[],"source":["%cd /content/drive/Othercomputers/Il mio MacBook Pro/real-time-style-transfer/chainer-fast-neuralstyle\n","path = \"/content/drive/Othercomputers/Il mio MacBook Pro/real-time-style-transfer/chainer-fast-neuralstyle\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36618,"status":"ok","timestamp":1690125181320,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"zDdj9Y5gGijf","outputId":"4ab78c7b-0d08-47da-a525-17cf41853423"},"outputs":[],"source":["!pip install chainer\n","!sh setup_model.sh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v17bbqk4MhOf"},"outputs":[],"source":["import os\n","if not os.path.exists('train2014.zip'):\n","  !wget http://images.cocodataset.org/zips/train2014.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1690125181321,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"vQFsDtr5O9nF","outputId":"3b73d973-95cc-4b2c-85e9-3e42eb6e4f4c"},"outputs":[],"source":["%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImvegJTLOw3x"},"outputs":[],"source":["#!unzip 'train2014.zip' -d './coco'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZGWWO762GaQT"},"outputs":[],"source":["#!python train.py -s './sample_images/test_style.png' -g 0 -d './coco/train2014'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l5uya35WfoU0"},"outputs":[],"source":["from __future__ import print_function, division\n","import numpy as np\n","import os, re\n","import argparse\n","import random\n","from PIL import Image\n","\n","from chainer import cuda, Variable, optimizers, serializers\n","from net import *\n","\n","def load_image(path, size):\n","    image = Image.open(path).convert('RGB')\n","    w,h = image.size\n","    if w < h:\n","        if w < size:\n","            image = image.resize((size, size*h//w))\n","            w, h = image.size\n","    else:\n","        if h < size:\n","            image = image.resize((size*w//h, size))\n","            w, h = image.size\n","    image = image.crop(((w-size)*0.5, (h-size)*0.5, (w+size)*0.5, (h+size)*0.5))\n","    return xp.asarray(image, dtype=np.float32).transpose(2, 0, 1)\n","\n","def gram_matrix(y):\n","    b, ch, h, w = y.data.shape\n","    features = F.reshape(y, (b, ch, w*h))\n","    gram = F.batch_matmul(features, features, transb=True)/np.float32(ch*w*h)\n","    return gram\n","\n","def total_variation(x):\n","    xp = cuda.get_array_module(x.data)\n","    b, ch, h, w = x.data.shape\n","    wh = Variable(xp.asarray([[[[1], [-1]], [[0], [0]], [[0], [0]]], [[[0], [0]], [[1], [-1]], [[0], [0]]], [[[0], [0]], [[0], [0]], [[1], [-1]]]], dtype=np.float32))\n","    ww = Variable(xp.asarray([[[[1, -1]], [[0, 0]], [[0, 0]]], [[[0, 0]], [[1, -1]], [[0, 0]]], [[[0, 0]], [[0, 0]], [[1, -1]]]], dtype=np.float32))\n","    return F.sum(F.convolution_2d(x, W=wh) ** 2) + F.sum(F.convolution_2d(x, W=ww) ** 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SWa3xbThYK7"},"outputs":[],"source":["batchsize = 7\n","style_image = './sample_images/test_style.png'\n","image_size = 256\n","n_epoch = 2\n","lambda_tv = 1e-6\n","lambda_f = 1.0\n","lambda_s = 5.0\n","lambda_noise = 1000.0\n","noise_range = 30\n","noise_count = 1000\n","style_prefix, _ = os.path.splitext(os.path.basename(style_image))\n","output = style_prefix\n","dataset = './coco/train2014'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oxlV9sOk-RRI"},"outputs":[],"source":["if os.path.exists('fs.list'):\n","  # leggo da qui i path che se no ci mette un anno\n","  with open('fs.list') as f:\n","    imagepaths = f.read().splitlines()\n","else:\n","  # devo creare la lista leggendo dalla cartella\n","  fs = os.listdir(dataset)\n","  imagepaths = []\n","  for fn in fs:\n","      base, ext = os.path.splitext(fn)\n","      if ext == '.jpg' or ext == '.png':\n","          imagepath = os.path.join(dataset, fn)\n","          imagepaths.append(imagepath)\n","  with open('fs.list','w') as tfile:\n","    tfile.write('\\n'.join(imagepaths))\n","\n","#fs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1690125527835,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"vjsoF7Syngvi","outputId":"de5382fd-cc38-44d9-d258-8f74f5bc64fe"},"outputs":[],"source":["n_data = len(imagepaths)\n","print('num traning images:', n_data)\n","n_iter = n_data // batchsize\n","print(n_iter, 'iterations,', n_epoch, 'epochs')\n","#82783"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1690125547179,"user":{"displayName":"Niccolò","userId":"04990246452610004701"},"user_tz":-120},"id":"e9t_gXIN7NuX","outputId":"2d5b380c-bb3e-452f-9d09-9e4346cffdfc"},"outputs":[],"source":["import glob\n","\n","def check_resume(style_name, higher=False):\n","  higher_it = 1 if higher else 0\n","\n","  query_model = glob.glob(f'./models/check_{style_name}*.model')\n","  if(query_model):\n","    assert len(query_model) == 2, \"dunno where to start, 1 or more than 2 checkpoints for the same model found\"\n","    query_model.sort()\n","    info = query_model[higher_it].split(\"/\")[-1].split(\".\")[0].split(\"_\")\n","    start_it_model = int(info[-1]) // batchsize\n","    start_epoch_model = int(info[-2])\n","\n","  query_state = glob.glob(f'./models/{style_name}*.state')\n","  if(query_state):\n","    assert len(query_state) == 2, \"dunno where to start, 1 or more than 2 checkpoints for the same state found\"\n","    query_state.sort()\n","    info = query_state[higher_it].split(\"/\")[-1].split(\".\")[0].split(\"_\")\n","    start_it_state = int(info[-1]) // batchsize\n","    start_epoch_state = int(info[-2])\n","\n","  if not query_model or not query_state:\n","    print(\"unmatching state and model found, starting over\")\n","    return None, None, 0, 0\n","\n","  if (start_epoch_model == start_epoch_state and start_it_model == start_it_state):\n","    initmodel = query_model[higher_it]\n","    resume = query_state[higher_it]\n","    return initmodel, resume, start_it_model, start_epoch_model\n","\n","check_resume(output, path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"yUzsVziCh1_x","outputId":"dcb02ac0-49e5-4cd0-8a2a-7a6922e9aada"},"outputs":[],"source":["checkpoint = 5\n","initmodel, resume, start_iteration, start_epoch = check_resume(output, path, True)\n","\n","gpu_code = 0\n","lr = 1e-3\n","\n","model = FastStyleNet()\n","vgg = VGG()\n","serializers.load_npz('vgg16.model', vgg)\n","\n","if initmodel:\n","    print('load model from', initmodel)\n","    serializers.load_npz(initmodel, model)\n","\n","if gpu_code >= 0:\n","    cuda.get_device(gpu_code).use()\n","    model.to_gpu()\n","    vgg.to_gpu()\n","xp = np if gpu_code < 0 else cuda.cupy\n","\n","O = optimizers.Adam(alpha=lr)\n","O.setup(model)\n","if resume:\n","    print('load optimizer state from', resume)\n","    serializers.load_npz(resume, O)\n","\n","style = vgg.preprocess(np.asarray(Image.open(style_image).convert('RGB').resize((image_size,image_size)), dtype=np.float32))\n","style = xp.asarray(style, dtype=xp.float32)\n","style_b = xp.zeros((batchsize,) + style.shape, dtype=xp.float32)\n","for i in range(batchsize):\n","    style_b[i] = style\n","feature_s = vgg(Variable(style_b))\n","gram_s = [gram_matrix(y) for y in feature_s]\n","\n","for epoch in range(start_epoch, n_epoch):\n","    print('epoch', epoch)\n","\n","    if noise_count:\n","        noiseimg = xp.zeros((3, image_size, image_size), dtype=xp.float32)\n","\n","        # prepare a noise image\n","        for ii in range(noise_count):\n","            xx = random.randrange(image_size)\n","            yy = random.randrange(image_size)\n","\n","            noiseimg[0][yy][xx] += random.randrange(-noise_range, noise_range)\n","            noiseimg[1][yy][xx] += random.randrange(-noise_range, noise_range)\n","            noiseimg[2][yy][xx] += random.randrange(-noise_range, noise_range)\n","\n","    slack = checkpoint*2 # 2 save only the last 2 checkpoints\n","    for i in range(start_iteration, n_iter):\n","        model.zerograds()\n","        vgg.zerograds()\n","\n","        indices = range(i * batchsize, (i+1) * batchsize)\n","        x = xp.zeros((batchsize, 3, image_size, image_size), dtype=xp.float32)\n","        for j in range(batchsize):\n","            x[j] = load_image(imagepaths[i*batchsize + j], image_size)\n","\n","        xc = Variable(x.copy())\n","\n","        if noise_count:\n","            # add the noise image to the source image\n","            noisy_x = x.copy()\n","            noisy_x = noisy_x + noiseimg\n","\n","            noisy_x = Variable(noisy_x)\n","            noisy_y = model(noisy_x)\n","            noisy_y -= 120\n","\n","        x = Variable(x)\n","\n","        y = model(x)\n","\n","        xc -= 120\n","        y -= 120\n","\n","        feature = vgg(xc)\n","        feature_hat = vgg(y)\n","\n","        L_feat = lambda_f * F.mean_squared_error(Variable(feature[2].data), feature_hat[2]) # compute for only the output of layer conv3_3\n","\n","        L_style = Variable(xp.zeros((), dtype=np.float32))\n","        for f, f_hat, g_s in zip(feature, feature_hat, gram_s):\n","            L_style += lambda_s * F.mean_squared_error(gram_matrix(f_hat), Variable(g_s.data))\n","\n","        L_tv = lambda_tv * total_variation(y)\n","\n","        # the 'popping' noise is the difference in resulting stylizations\n","        # from two images that are very similar. Minimizing it results\n","        # in a much more stable stylization that can be applied to video.\n","        # Small changes in the input result in small changes in the output.\n","        if noise_count:\n","            L_pop = lambda_noise * F.mean_squared_error(y, noisy_y)\n","            L = L_feat + L_style + L_tv + L_pop\n","            print('Epoch {},{}/{}. Total loss: {}. Loss distribution: feat {}, style {}, tv {}, pop {}'\n","                         .format(epoch, i, n_iter, L.data,\n","                                 L_feat.data/L.data, L_style.data/L.data,\n","                                 L_tv.data/L.data, L_pop.data/L.data))\n","        else:\n","            L = L_feat + L_style + L_tv\n","            print('Epoch {},{}/{}. Total loss: {}. Loss distribution: feat {}, style {}, tv {}'\n","                         .format(epoch, i, n_iter, L.data,\n","                                 L_feat.data/L.data, L_style.data/L.data,\n","                                 L_tv.data/L.data))\n","\n","        L.backward()\n","        O.update()\n","\n","        if checkpoint > 0 and i % checkpoint == 0:\n","            if i >= start_iteration + slack:\n","                os.remove('models/check_{}_{}_{}.model'.format(output, epoch, i - slack))\n","                os.remove('models/check_{}_{}_{}.state'.format(output, epoch, i - slack))\n","            serializers.save_npz('models/check_{}_{}_{}.model'.format(output, epoch, i), model)\n","            serializers.save_npz('models/check_{}_{}_{}.state'.format(output, epoch, i), O)\n","\n","    #print('save \"style.model\"')\n","    #serializers.save_npz('models/{}_{}.model'.format(output, epoch), model)\n","    #serializers.save_npz('models/{}_{}.state'.format(output, epoch), O)\n","\n","serializers.save_npz('models/{}.model'.format(output), model)\n","serializers.save_npz('models/{}.state'.format(output), O)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADFN8rRHyWAt"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
